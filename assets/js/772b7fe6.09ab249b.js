"use strict";(self.webpackChunkproject_website=self.webpackChunkproject_website||[]).push([[836],{3905:(e,r,t)=>{t.d(r,{Zo:()=>p,kt:()=>m});var n=t(7294);function a(e,r,t){return r in e?Object.defineProperty(e,r,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[r]=t,e}function i(e,r){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);r&&(n=n.filter((function(r){return Object.getOwnPropertyDescriptor(e,r).enumerable}))),t.push.apply(t,n)}return t}function o(e){for(var r=1;r<arguments.length;r++){var t=null!=arguments[r]?arguments[r]:{};r%2?i(Object(t),!0).forEach((function(r){a(e,r,t[r])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):i(Object(t)).forEach((function(r){Object.defineProperty(e,r,Object.getOwnPropertyDescriptor(t,r))}))}return e}function s(e,r){if(null==e)return{};var t,n,a=function(e,r){if(null==e)return{};var t,n,a={},i=Object.keys(e);for(n=0;n<i.length;n++)t=i[n],r.indexOf(t)>=0||(a[t]=e[t]);return a}(e,r);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(n=0;n<i.length;n++)t=i[n],r.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(a[t]=e[t])}return a}var c=n.createContext({}),l=function(e){var r=n.useContext(c),t=r;return e&&(t="function"==typeof e?e(r):o(o({},r),e)),t},p=function(e){var r=l(e.components);return n.createElement(c.Provider,{value:r},e.children)},u="mdxType",d={inlineCode:"code",wrapper:function(e){var r=e.children;return n.createElement(n.Fragment,{},r)}},f=n.forwardRef((function(e,r){var t=e.components,a=e.mdxType,i=e.originalType,c=e.parentName,p=s(e,["components","mdxType","originalType","parentName"]),u=l(t),f=a,m=u["".concat(c,".").concat(f)]||u[f]||d[f]||i;return t?n.createElement(m,o(o({ref:r},p),{},{components:t})):n.createElement(m,o({ref:r},p))}));function m(e,r){var t=arguments,a=r&&r.mdxType;if("string"==typeof e||a){var i=t.length,o=new Array(i);o[0]=f;var s={};for(var c in r)hasOwnProperty.call(r,c)&&(s[c]=r[c]);s.originalType=e,s[u]="string"==typeof e?e:a,o[1]=s;for(var l=2;l<i;l++)o[l]=t[l];return n.createElement.apply(null,o)}return n.createElement.apply(null,t)}f.displayName="MDXCreateElement"},8368:(e,r,t)=>{t.r(r),t.d(r,{assets:()=>c,contentTitle:()=>o,default:()=>d,frontMatter:()=>i,metadata:()=>s,toc:()=>l});var n=t(7462),a=(t(7294),t(3905));const i={sidebar_position:8},o="Real-Time Digital Twins: Vision and Research Directions for 6G and Beyond",s={unversionedId:"references/paper8",id:"references/paper8",title:"Real-Time Digital Twins: Vision and Research Directions for 6G and Beyond",description:"Ahmed Alkhateeb, Shuaifeng Jiang & Gouranga Charan",source:"@site/docs/references/paper8.md",sourceDirName:"references",slug:"/references/paper8",permalink:"/docs/references/paper8",draft:!1,tags:[],version:"current",sidebarPosition:8,frontMatter:{sidebar_position:8},sidebar:"tutorialSidebar",previous:{title:"Collaboration as a Service: Digital-Twin-Enabled Collaborative and Distributed Autonomous Driving",permalink:"/docs/references/paper7"},next:{title:"Life cycle management of automotive data functions in MEC infrastructures",permalink:"/docs/references/paper9"}},c={},l=[{value:"Ahmed Alkhateeb, Shuaifeng Jiang &amp; Gouranga Charan",id:"ahmed-alkhateeb-shuaifeng-jiang--gouranga-charan",level:3},{value:"Abstract",id:"abstract",level:2},{value:"Full Report",id:"full-report",level:2}],p={toc:l},u="wrapper";function d(e){let{components:r,...t}=e;return(0,a.kt)(u,(0,n.Z)({},p,t,{components:r,mdxType:"MDXLayout"}),(0,a.kt)("h1",{id:"real-time-digital-twins-vision-and-research-directions-for-6g-and-beyond"},"Real-Time Digital Twins: Vision and Research Directions for 6G and Beyond"),(0,a.kt)("h3",{id:"ahmed-alkhateeb-shuaifeng-jiang--gouranga-charan"},"Ahmed Alkhateeb, Shuaifeng Jiang & Gouranga Charan"),(0,a.kt)("h2",{id:"abstract"},"Abstract"),(0,a.kt)("p",null,"This article presents a vision where real-time digital twins of the physical wireless environments are continuously updated using multi-modal sensing data from the distributed infrastructure and user devices, and are used to make communication and sensing decisions. This vision is mainly enabled by the advances in precise 3D maps, multi-modal sensing, ray-tracing computations, and machine/deep learning. This article details this vision, explains the different approaches for constructing and utilizing these real-time digital twins, discusses the applications and open problems, and presents a research platform that can be used to investigate various digital twin research directions."),(0,a.kt)("h2",{id:"full-report"},"Full Report"),(0,a.kt)("p",null,"Read the complete file, ",(0,a.kt)("a",{parentName:"p",href:"https://arxiv.org/pdf/2301.11283.pdf"},"here"),"."))}d.isMDXComponent=!0}}]);